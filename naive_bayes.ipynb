{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Sentiment Analysis Challenge\n",
    "#### Naive Bayes Implementation\n",
    "For my \"from scratch\" implementation I've done fairly basic naive bayes. I attempted to add\n",
    "things that would account for more complex features such as data cleaning and word pair\n",
    "analysis but, surprisingly, these reduced accuracy significantly. I'll talk more about those\n",
    "experiments throughout the notebook."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "import csv\n",
    "import math"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set Input Variables Here\n",
    "**To input test data, simply add it to the data directory and set `test_file` to the relative\n",
    "filepath. If `test_file` has a value, `validation_percent` will be ignored and no validation\n",
    "set will be used.**\n",
    "\n",
    "Set `using_word_pairs` to True to add word pair analysis. This essentially creates\n",
    "a word pair \"bag of words\" that is also factored into the prediction. With the Welsh tweets,\n",
    "this performs significantly worse. After playing around with Google translate for a bit, my\n",
    "theory as to why this is two fold.\n",
    "\n",
    "For one, certain Welsh words that are highly connected don't\n",
    "necessarily appear together. For example, a sentence that can easily fool basic naive\n",
    "bayes is \"I'm not happy\". Happy definitely has a very high positive probability and without\n",
    "word pairs \"not happy\" cannot be recognized as highly negative. However, in Welsh, \"not\" is\n",
    "\"ddim\" and \"happy\" is \"hapus\". However \"I'm not happy\" is \"Dwi ddim yn hapus\". The words\n",
    "for \"not\" and \"happy\" don't appear next to each other as they do in English, so triple word\n",
    "combinations (or more) would have to be used to recognize this in Welsh.\n",
    "I considered translating each tweet to English and then running the word pair analysis but\n",
    "could not do so considering this is the \"from scratch\" rather than the \"anything goes\"\n",
    "implementation.\n",
    "\n",
    "Secondly, I don't think the dataset is large enough to statistically recognize if a string of 2+\n",
    "words is positive or negative (won't have enough non-unique combinations) with something\n",
    "as simple as naive bayes.\n",
    "\n",
    "**Note: for highest accuracy on the Welsh language tweets dataset, make sure `using_word_pairs` is set to `False`**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [],
   "source": [
    "train_file = 'data/train.tsv'\n",
    "validation_percent = 0.1\n",
    "test_file = ''\n",
    "using_word_pairs = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import the data from provided file, only including valid rows with both labels and data.\n",
    "There were a few inputs that did not have labels so this has a simple data cleaning check\n",
    "to confirm both a label and a document are present before adding."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Loaded 78608 documents\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading training data...\")\n",
    "labels = []\n",
    "inputs = []\n",
    "with open(train_file, encoding='utf-8') as data:\n",
    "  reader = csv.reader(data, delimiter='\\t')\n",
    "  for row in reader:\n",
    "    if len(row) == 2:\n",
    "        labels.append(row[0])\n",
    "        inputs.append(row[1])\n",
    "print(\"Loaded {} documents\".format(len(labels)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This does the same as above for the test file if one is provided. If not, it splits the training\n",
    "data into a train set and validation split based on the split provided in the *Inputs* cell."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting training and validation sets...\n",
      "Training set has 70747 documents\n",
      "Validation set has 7861 documents\n"
     ]
    }
   ],
   "source": [
    "if len(test_file) > 0:\n",
    "    print(\"Loading testing data...\")\n",
    "    with open(test_file, encoding='utf-8') as data:\n",
    "      reader = csv.reader(data, delimiter='\\t')\n",
    "      test_labels = []\n",
    "      test_inputs = []\n",
    "      for row in reader:\n",
    "        if len(row) == 2:\n",
    "            test_labels.append(row[0])\n",
    "            test_inputs.append(row[1])\n",
    "    print(\"Loaded {} documents\".format(len(test_labels)))\n",
    "    train_labels = labels\n",
    "    train_inputs = inputs\n",
    "else:\n",
    "    print(\"Splitting training and validation sets...\")\n",
    "    num_train_samples = int(len(labels) * (1-validation_percent))\n",
    "    train_labels = labels[:num_train_samples]\n",
    "    train_inputs = inputs[:num_train_samples]\n",
    "    test_labels = labels[num_train_samples:]\n",
    "    test_inputs = inputs[num_train_samples:]\n",
    "    print(\"Training set has {} documents\".format(len(train_labels)))\n",
    "    print(\"Validation set has {} documents\".format(len(test_labels)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `count_words` function counts the number of positive and negative occurrences of each\n",
    "word and returns the counts in dictionary form.\n",
    "\n",
    "I tested punctuation removal and lowercase normalizing here but both performed\n",
    "significantly (at least 3%) worse on validation data. I suspect this is because things like\n",
    "exclamation marks or all caps are reasonably accurate predictors of sentiment, especially\n",
    "binary positive vs negative sentiment."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "def count_words(documents_list):\n",
    "    print(\"Counting words...\")\n",
    "    _counts = {'positive': {}, 'negative': {}}\n",
    "    for _idx, document in enumerate(documents_list):\n",
    "            _sentiment = 'positive' if int(labels[_idx]) else 'negative'\n",
    "            for word in document.split():\n",
    "                if word in _counts[_sentiment]:\n",
    "                    _counts[_sentiment][word] += 1\n",
    "                else:\n",
    "                    _counts[_sentiment][word] = 1\n",
    "    print(\"Counted {} positive, {} negative words\".format(len(_counts['positive']), len(_counts['negative'])))\n",
    "    return _counts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This function is the same as above except it counts word pairs (each word and the word following).\n",
    "This won't be used if `using_word_pairs` is set to `False`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [],
   "source": [
    "def count_word_pairs(documents_list):\n",
    "    print(\"Counting word pairs...\")\n",
    "    _counts = {'positive': {}, 'negative': {}}\n",
    "    for _idx, document in enumerate(documents_list):\n",
    "            _sentiment = 'positive' if int(labels[_idx]) else 'negative'\n",
    "            _word_list = document.split()\n",
    "            for word_place, word in enumerate(_word_list):\n",
    "                if word_place < len(_word_list)-1:\n",
    "                    word_pair = word + ' ' + _word_list[word_place+1]\n",
    "                    if word_pair in _counts[_sentiment]:\n",
    "                        _counts[_sentiment][word_pair] += 1\n",
    "                    else:\n",
    "                        _counts[_sentiment][word_pair] = 1\n",
    "    print(\"Counted {} positive, {} negative word pairs\".format(len(_counts['positive']), len(_counts['negative'])))\n",
    "    return _counts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`fit` calculates the probabilities of a word (or word pair) being present given the class.\n",
    "As per the Naive Bayes setup in the textbook it's based on the word count and size of each class's \"bag of words\".\n",
    "While I include Laplace smoothing below if a word hasn't been encountered yet, I don't add 1 here\n",
    "simply because it caused significantly worse performance in my experiments. I'm not entirely sure why this is."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing probabilities...\n",
      "Counting words...\n",
      "Counted 75833 positive, 72061 negative words\n",
      "Counting word pairs...\n",
      "Counted 299951 positive, 290987 negative word pairs\n"
     ]
    }
   ],
   "source": [
    "def fit_words(_inputs):\n",
    "    _probabilities = count_words(_inputs)\n",
    "    num_positive = len(_probabilities['positive'])\n",
    "    num_negative = len(_probabilities['negative'])\n",
    "    for pos_word in _probabilities['positive']:\n",
    "        _probabilities['positive'][pos_word] = math.log(_probabilities['positive'][pos_word] / num_positive)\n",
    "    for neg_word in _probabilities['negative']:\n",
    "        _probabilities['negative'][neg_word] = math.log(_probabilities['negative'][neg_word] / num_negative)\n",
    "    return _probabilities\n",
    "\n",
    "def fit_pairs(_inputs):\n",
    "    _pair_probabilities = count_word_pairs(_inputs)\n",
    "    num_positive = len(_pair_probabilities['positive'])\n",
    "    num_negative = len(_pair_probabilities['negative'])\n",
    "    for pos_pair in _pair_probabilities['positive']:\n",
    "        _pair_probabilities['positive'][pos_pair] = math.log(_pair_probabilities['positive'][pos_pair] / num_positive)\n",
    "    for neg_pair in _pair_probabilities['negative']:\n",
    "        _pair_probabilities['negative'][neg_pair] = math.log(_pair_probabilities['negative'][neg_pair] / num_negative)\n",
    "    return _pair_probabilities\n",
    "\n",
    "def fit(_inputs):\n",
    "    print(\"Computing probabilities...\")\n",
    "    return fit_words(_inputs), fit_pairs(_inputs)\n",
    "\n",
    "word_probabilities, pair_probabilities = fit(train_inputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "These functions are simply to retrieve the probabilities if a word has been seen before,\n",
    "and to return 1 / the word count (Laplace smoothing) if not."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "def get_positive_word_probability(_word):\n",
    "    if _word in word_probabilities['positive']:\n",
    "        return word_probabilities['positive'][_word]\n",
    "    else:\n",
    "        return math.log(1 / len(word_probabilities['positive']))\n",
    "def get_negative_word_probability(_word):\n",
    "    if _word in word_probabilities['negative']:\n",
    "        return word_probabilities['negative'][_word]\n",
    "    else:\n",
    "        return math.log(1 / len(word_probabilities['negative']))\n",
    "def get_positive_pair_probability(_pair):\n",
    "    if _pair in pair_probabilities['positive']:\n",
    "        return pair_probabilities['positive'][_pair]\n",
    "    else:\n",
    "        return math.log(1 / len(word_probabilities['positive']))\n",
    "def get_negative_pair_probability(_pair):\n",
    "    if _pair in pair_probabilities['negative']:\n",
    "        return pair_probabilities['negative'][_pair]\n",
    "    else:\n",
    "        return math.log(1 / len(pair_probabilities['negative']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`predict` adds the positive probabilities and the negative probabilities and compares, returning the higher\n",
    "probability as the prediction."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "def predict(_document):\n",
    "    positive_sum = 0\n",
    "    negative_sum = 0\n",
    "    _word_list = _document.split()\n",
    "    for _idx, _word in enumerate(_word_list):\n",
    "        positive_sum += get_positive_word_probability(_word)\n",
    "        negative_sum += get_negative_word_probability(_word)\n",
    "        if using_word_pairs and _idx < len(_word_list)-1:\n",
    "            positive_sum += get_positive_pair_probability(_word + ' ' + _word_list[_idx+1])\n",
    "            negative_sum += get_negative_pair_probability(_word + ' ' + _word_list[_idx+1])\n",
    "    return 1 if positive_sum > negative_sum else 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This runs the algorithm and returns the validation/test accuracy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running...\n",
      "Done!\n",
      "Validation Accuracy: 73.54%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "print(\"Running...\")\n",
    "for idx, doc in enumerate(test_inputs):\n",
    "    if predict(doc) == int(test_labels[idx]):\n",
    "        correct += 1\n",
    "print(\"Done!\")\n",
    "val_or_test = \"Validation\" if len(test_file) <= 0 else \"Testing\"\n",
    "print(\"{} Accuracy:\".format(val_or_test), str(round(correct / len(test_inputs) * 100, 2))+\"%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-310db17d",
   "language": "python",
   "display_name": "PyCharm (sentiment_analysis)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}